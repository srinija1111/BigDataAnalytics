{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19d74c88-f9dd-480a-9f65-116c0de156ac",
   "metadata": {},
   "source": [
    "**Explore how the collect() operation works in pyspark using dataset with basic RDD operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b758ea06-e65d-4a96-a3e8-5709987f1205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-83C5GA1:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9b9c01d-484a-410c-821b-711be2a5b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.textFile(\"students.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f80b8c7b-2659-40c4-91f0-2f78dc35ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = data.first()\n",
    "rows = data.filter(lambda line: line != header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ed076dd-751e-4a19-9d7c-2a2dd14b592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_rdd = rows.map(lambda line: line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66331d19-288a-48d9-bf2f-99c6352a59c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Student Dataset (first 10 rows) ===\n",
      "['1', 'Alice', '20', 'F', '66', '92', '44']\n",
      "['2', 'Bob', '20', 'M', '82', '52', '77']\n",
      "['3', 'Charlie', '22', 'F', '43', '57', '76']\n",
      "['4', 'David', '19', 'M', '95', '69', '46']\n",
      "['5', 'Eva', '19', 'F', '62', '44', '96']\n",
      "['6', 'Frank', '22', 'F', '70', '78', '94']\n",
      "['7', 'Grace', '24', 'F', '67', '66', '93']\n",
      "['8', 'Henry', '21', 'F', '53', '82', '60']\n",
      "['9', 'Ivy', '19', 'M', '64', '52', '46']\n",
      "['10', 'Jack', '19', 'F', '44', '59', '60']\n"
     ]
    }
   ],
   "source": [
    " print(\"=== Student Dataset (first 10 rows) ===\")\n",
    " for row in split_rdd.take(10):   # you can change 10 â†’ 20, 50 etc.\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c17a308a-6f98-445a-855a-d1791cc7092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_rdd = split_rdd.map(lambda x: (int(x[0]), x[1], int(x[2]), x[3], int(x[4]), int(x[5]), int(x[6])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7dff1b0-40fc-4aa9-90ee-150a1f845699",
   "metadata": {},
   "outputs": [],
   "source": [
    " avg_marks_rdd = students_rdd.map(lambda x: (x[1], (x[4] + x[5] + x[6]) / 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fda552bd-af75-4683-8689-9282f115b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    " passed_rdd = avg_marks_rdd.filter(lambda x: x[1] >= 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d64bad71-e781-4efd-b8f9-5ff2cbc53ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    " sorted_passed_rdd = passed_rdd.sortBy(lambda x: x[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6449787-4a96-4665-aeef-8539d4bf574e",
   "metadata": {},
   "outputs": [],
   "source": [
    " results = sorted_passed_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "148dd35f-b5fc-48e4-b1f1-45ccb24a3114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Students with Average >= 75 ===\n",
      "Name: Leo, Avg Marks: 88.00\n",
      "Name: Olivia, Avg Marks: 88.00\n",
      "Name: Rita, Avg Marks: 86.67\n",
      "Name: Kathy, Avg Marks: 81.67\n",
      "Name: George, Avg Marks: 81.67\n",
      "Name: Frank, Avg Marks: 80.67\n",
      "Name: Oscar, Avg Marks: 80.00\n",
      "Name: Uma, Avg Marks: 78.33\n",
      "Name: Kyle, Avg Marks: 78.33\n",
      "Name: Matt, Avg Marks: 78.33\n",
      "Name: Tina, Avg Marks: 76.00\n",
      "Name: Victor, Avg Marks: 75.67\n",
      "Name: Grace, Avg Marks: 75.33\n",
      "Name: Mona, Avg Marks: 75.00\n",
      "Name: Will, Avg Marks: 75.00\n"
     ]
    }
   ],
   "source": [
    " print(\"=== Students with Average >= 75 ===\")\n",
    " for student in results:\n",
    "    print(f\"Name: {student[0]}, Avg Marks: {student[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44521f3d-0b85-4c93-ae55-dfa6f74ad4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of students who passed: 15\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Some extra RDD operations for practice\n",
    " # (a) Count how many students passed\n",
    "count_passed = passed_rdd.count()\n",
    "print(\"\\nNumber of students who passed:\", count_passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b591736-5ccb-42d8-96d2-9aa1ae2b280e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topper: ('Olivia', 88.0)\n"
     ]
    }
   ],
   "source": [
    " # (b) Find max average scorer\n",
    " topper = passed_rdd.reduce(lambda a, b: a if a[1] > b[1] else b)\n",
    " print(\"Topper:\", topper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7beba63-d164-46d7-880c-c048210e98b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 Passed Students (via take):\n",
      "[('Frank', 80.66666666666667), ('Grace', 75.33333333333333), ('Kathy', 81.66666666666667), ('Leo', 88.0), ('Mona', 75.0)]\n"
     ]
    }
   ],
   "source": [
    " # (c) Show first 5 passed students\n",
    " print(\"\\nFirst 5 Passed Students (via take):\")\n",
    " print(passed_rdd.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf4dc5d-3007-4889-a717-4324e6205ee6",
   "metadata": {},
   "source": [
    "**CONCLUSION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77db543-e544-4273-824f-c79e59c51fea",
   "metadata": {},
   "source": [
    "The experiment demonstrates that collect() is a powerful action in PySpark that retrieves all elements of an RDD back to the driver for further use. \n",
    "In this example, it was used to display students with high averages after applying transformations like map, filter, and sortBy. However, collect() \n",
    "should be used cautiously on large datasets since it brings all data into driver memory, which can cause performance or memory issues. For large-scale \n",
    "applications, safer alternatives like take(), count(), or writing results to external storage (HDFS, database, file) are preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be434bd8-4d4f-4599-91c4-7a2f21cb74c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

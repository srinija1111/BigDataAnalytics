{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79197654-cfff-4dd1-9fcc-7fa54c394b8d",
   "metadata": {},
   "source": [
    "**Create a DatasetFrame in pyspark and apply basic operations such as viewing data and selecting columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81f0eb76-793b-4d3f-8e18-f6b4af5bbe27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-83C5GA1:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0a0ea9-51e0-4449-8a42-e4070d79ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    " # Step 1: Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"BasicDataFrameOps\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01d606d1-472f-4c7f-b654-a0655aae1898",
   "metadata": {},
   "outputs": [],
   "source": [
    " df = spark.read.csv(\"students.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89cd7fb9-1448-4f47-acef-839632b0255a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== First 5 rows ===\n",
      "+---+-------+---+------+----+-------+-------+\n",
      "| id|   name|age|gender|math|science|english|\n",
      "+---+-------+---+------+----+-------+-------+\n",
      "|  1|  Alice| 20|     F|  66|     92|     44|\n",
      "|  2|    Bob| 20|     M|  82|     52|     77|\n",
      "|  3|Charlie| 22|     F|  43|     57|     76|\n",
      "|  4|  David| 19|     M|  95|     69|     46|\n",
      "|  5|    Eva| 19|     F|  62|     44|     96|\n",
      "+---+-------+---+------+----+-------+-------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    " print(\"=== First 5 rows ===\")\n",
    " df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea9afb49-b839-4af1-80af-f512d1e71436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Schema ===\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- math: integer (nullable = true)\n",
      " |-- science: integer (nullable = true)\n",
      " |-- english: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    " print(\"=== Schema ===\")\n",
    " df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3de4e768-f868-4131-9b28-4e8a499e3f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Select name and math columns ===\n",
      "+-------+----+\n",
      "|   name|math|\n",
      "+-------+----+\n",
      "|  Alice|  66|\n",
      "|    Bob|  82|\n",
      "|Charlie|  43|\n",
      "|  David|  95|\n",
      "|    Eva|  62|\n",
      "+-------+----+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Select name and math columns ===\")\n",
    "df.select(\"name\", \"math\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddd6e32d-2b4c-4db4-b1fc-5a5dd91be46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Students with math >= 80 ===\n",
      "+---+------+---+------+----+-------+-------+\n",
      "| id|  name|age|gender|math|science|english|\n",
      "+---+------+---+------+----+-------+-------+\n",
      "|  2|   Bob| 20|     M|  82|     52|     77|\n",
      "|  4| David| 19|     M|  95|     69|     46|\n",
      "| 11| Kathy| 25|     M|  85|     71|     89|\n",
      "| 12|   Leo| 24|     M|  97|     84|     83|\n",
      "| 15|Olivia| 18|     M|  87|     90|     87|\n",
      "+---+------+---+------+----+-------+-------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    " print(\"=== Students with math >= 80 ===\")\n",
    " df.filter(df.math >= 80).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97398434-7d43-4f5e-a7bc-17c8890f5410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in dataset: 50\n"
     ]
    }
   ],
   "source": [
    " # 6. Count total rows\n",
    "print(\"Total rows in dataset:\", df.count())\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba4f045b-a0a6-443e-81dd-d74e70cc5aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['id', 'name', 'age', 'gender', 'math', 'science', 'english']\n"
     ]
    }
   ],
   "source": [
    "# 7. Show column names\n",
    "print(\"Columns:\", df.columns)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a95d9-7402-4050-87c0-0bf37110f2d4",
   "metadata": {},
   "source": [
    "**CONCLUSION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1786de26-fb91-49c8-9617-f9386bc0f51a",
   "metadata": {},
   "source": [
    "This exercise illustrates how to create a DataFrame in PySpark and perform basic operations like viewing, filtering, selecting, and sorting data. \n",
    "Unlike RDDs, DataFrames provide a structured format with schema, making queries more readable and efficient. With built-in functions and SQL-like \n",
    "operations, DataFrames enable fast and scalable data exploration and preprocessing, which is especially useful when working with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ad436a-2dd4-4a71-8e1c-fa86a8df2f72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
